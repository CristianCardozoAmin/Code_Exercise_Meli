# Opportunities@MeLi - Ejercicio T茅cnico de Machine Learning

## Introducci贸n y objetivo
El objetivo principal de este ejercicio es desarrollar un algoritmo que prediga si un 铆tem publicado en MercadoLibre es **nuevo (0)** o **usado (1)** a partir de la informaci贸n disponible en los datos.

---

## Estructura del Proyecto

###  Notebooks
- `exploratory_analysis.ipynb`: An谩lisis exploratorio inicial (EDA).
- `model_01.ipynb`: Desarrollo del modelo usando **XGBoost**.
- `model_02.ipynb`: Desarrollo del modelo usando **LightGBM**.

###  Scripts Python
- `Preprocessing.py`: Transformaci贸n inicial del JSON en datos tabulares manejables.
- `Transformation.py`: Aplicaci贸n de transformaciones espec铆ficas identificadas en el EDA.
- `model_processing.py`: Preparaci贸n final de los datos (normalizaci贸n, codificaci贸n dummy y conversi贸n de booleanos).
- `new_or_used.py`: C贸digo para desplegar el modelo en producci贸n usando FastAPI.

---

## Descripci贸n de los datos
Los datos iniciales se obtienen de una API en formato JSON, que contiene estructuras anidadas complejas. Se utiliz贸 una funci贸n recursiva implementada en `Preprocessing.py` para convertir estas estructuras en columnas 煤tiles para Machine Learning.

Luego, mediante un An谩lisis Exploratorio Autom谩tico (EDA), se identificaron variables 煤tiles, completitud de datos y transformaciones necesarias.

---

## Transformaciones realizadas
Las transformaciones claves implementadas en `Transformation.py` fueron:

- **Conversi贸n de moneda:** Homogeneizaci贸n a pesos argentinos considerando tasas hist贸ricas.
- **Extracci贸n de componentes temporales:** Separaci贸n de fecha y hora en variables num茅ricas individuales (a帽o, mes, d铆a, semana ISO, d铆a de la semana, hora, minuto, segundo).
- **Transformaci贸n de variables categ贸ricas:**
  - Conversi贸n a booleanas si la cantidad de nulos es alta.
  - Reducci贸n de categor铆as dominantes a variables binarias.
  - Transformaci贸n de variables ordinales a num茅ricas.
- **Extracci贸n de coordenadas geogr谩ficas:** Uso de la API de MercadoLibre para obtener latitud y longitud.
- **Eliminaci贸n de variables:**
  - Variables con m谩s del 95% de valores nulos.
  - Variables con alta cardinalidad o identificadores 煤nicos (URLs).
- **Conversi贸n de dimensiones de fotos:** Separaci贸n de dimensiones en alto y ancho.

Estas transformaciones se complementan con las preparaciones finales definidas en `model_processing.py`, incluyendo estandarizaci贸n y codificaci贸n dummy.

---

## Modelos utilizados
Para resolver el problema de clasificaci贸n se utilizaron dos modelos robustos ante valores faltantes y multicolinealidad:

- **Extreme Gradient Boosting (XGBoost)**
- **Light Gradient Boosting (LightGBM)**

Ambos modelos se optimizaron utilizando `GridSearchCV` y la m茅trica principal solicitada fue el **Accuracy**.

---

## Desempe帽o de los Modelos

| Modelo          | Accuracy | F1-score | AUC ROC |
|-----------------|----------|----------|---------|
| XGBoost         | **0.881**    | **0.875**    | **0.95** |
| LightGBM        | 0.8733   | 0.8675   | 0.95 |

Se recomienda como m茅trica secundaria el 谩rea bajo la curva ROC (**AUC**), por su capacidad intuitiva para evaluar el desempe帽o del modelo en t茅rminos de falsos positivos y verdaderos positivos.

---

## Despliegue
El modelo final fue desplegado usando **FastAPI** para ofrecer una API sencilla que consume una base de datos como input y retorna la predicci贸n correspondiente. El c贸digo para esta tarea se encuentra en:

- `api_model_serving.py`

